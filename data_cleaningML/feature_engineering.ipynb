{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5acacc02",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Feature Engineering: Scaling, Normalization and Standardization**\n",
    "\n",
    "Feature engineering is the process of **creating**, **transforming**, or **selecting** the most relevant variables (features) from raw data to improve model performance.\n",
    "Well-designed features help machine learning models recognize important patterns and relationships, directly influencing how effectively the model learns.\n",
    "\n",
    "---\n",
    "\n",
    "## **Why Feature Engineering Matters**\n",
    "\n",
    "Feature engineering contributes to model building in several important ways:\n",
    "\n",
    "* **Improves Learning:**\n",
    "  Well-designed features allow models to capture complex patterns more effectively.\n",
    "\n",
    "* **Enhances Accuracy:**\n",
    "  Reduces noise and irrelevant information, leading to better predictions.\n",
    "\n",
    "* **Prevents Overfitting:**\n",
    "  Emphasizes meaningful signals, helping models generalize to unseen data.\n",
    "\n",
    "* **Simplifies Interpretation:**\n",
    "  Creates more informative and understandable inputs.\n",
    "\n",
    "There are several techniques used for feature engineering, including **scaling**, **normalization**, and **standardization**.\n",
    "Below is one commonly used method.\n",
    "\n",
    "---\n",
    "\n",
    "# **1. Absolute Maximum Scaling**\n",
    "\n",
    "Absolute Maximum Scaling rescales each feature by dividing all values by the **maximum absolute value** of that feature.\n",
    "This transformation ensures that feature values lie within the range **–1 to 1**.\n",
    "\n",
    "### **Formula**\n",
    "\n",
    "```text\n",
    "X_scaled = Xi / max(|X|)\n",
    "```\n",
    "\n",
    "### **Key Characteristics**\n",
    "\n",
    "* Scales values to the range **–1 to 1**\n",
    "* Simple to apply\n",
    "* **Highly sensitive to outliers**, since extreme values can distort the scaling\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e67aa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Area Income</th>\n",
       "      <th>Avg. Area House Age</th>\n",
       "      <th>Avg. Area Number of Rooms</th>\n",
       "      <th>Avg. Area Number of Bedrooms</th>\n",
       "      <th>Area Population</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79545.45857</td>\n",
       "      <td>5.682861</td>\n",
       "      <td>7.009188</td>\n",
       "      <td>4.09</td>\n",
       "      <td>23086.80050</td>\n",
       "      <td>1.059034e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79248.64245</td>\n",
       "      <td>6.002900</td>\n",
       "      <td>6.730821</td>\n",
       "      <td>3.09</td>\n",
       "      <td>40173.07217</td>\n",
       "      <td>1.505891e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61287.06718</td>\n",
       "      <td>5.865890</td>\n",
       "      <td>8.512727</td>\n",
       "      <td>5.13</td>\n",
       "      <td>36882.15940</td>\n",
       "      <td>1.058988e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63345.24005</td>\n",
       "      <td>7.188236</td>\n",
       "      <td>5.586729</td>\n",
       "      <td>3.26</td>\n",
       "      <td>34310.24283</td>\n",
       "      <td>1.260617e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59982.19723</td>\n",
       "      <td>5.040555</td>\n",
       "      <td>7.839388</td>\n",
       "      <td>4.23</td>\n",
       "      <td>26354.10947</td>\n",
       "      <td>6.309435e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
       "0       79545.45857             5.682861                   7.009188   \n",
       "1       79248.64245             6.002900                   6.730821   \n",
       "2       61287.06718             5.865890                   8.512727   \n",
       "3       63345.24005             7.188236                   5.586729   \n",
       "4       59982.19723             5.040555                   7.839388   \n",
       "\n",
       "   Avg. Area Number of Bedrooms  Area Population         Price  \n",
       "0                          4.09      23086.80050  1.059034e+06  \n",
       "1                          3.09      40173.07217  1.505891e+06  \n",
       "2                          5.13      36882.15940  1.058988e+06  \n",
       "3                          3.26      34310.24283  1.260617e+06  \n",
       "4                          4.23      26354.10947  6.309435e+05  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('housing.csv')\n",
    "\n",
    "df = df.select_dtypes(include=np.number)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebdb084",
   "metadata": {},
   "source": [
    "**Performing Absolute Maximum Scaling**\n",
    "\n",
    "Computes max absolute value per column with np.max(np.abs(df), axis=0).\n",
    "\n",
    "\n",
    "Divides each value by that max absolute to scale features between -1 and 1.\n",
    "\n",
    "Displays first few rows of scaled data with scaled_df.head()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2342830d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Area Income</th>\n",
       "      <th>Avg. Area House Age</th>\n",
       "      <th>Avg. Area Number of Rooms</th>\n",
       "      <th>Avg. Area Number of Bedrooms</th>\n",
       "      <th>Area Population</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.738572</td>\n",
       "      <td>0.596996</td>\n",
       "      <td>0.651436</td>\n",
       "      <td>0.629231</td>\n",
       "      <td>0.331603</td>\n",
       "      <td>0.428921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.735816</td>\n",
       "      <td>0.630617</td>\n",
       "      <td>0.625565</td>\n",
       "      <td>0.475385</td>\n",
       "      <td>0.577019</td>\n",
       "      <td>0.609903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.569044</td>\n",
       "      <td>0.616224</td>\n",
       "      <td>0.791176</td>\n",
       "      <td>0.789231</td>\n",
       "      <td>0.529751</td>\n",
       "      <td>0.428902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.588154</td>\n",
       "      <td>0.755139</td>\n",
       "      <td>0.519233</td>\n",
       "      <td>0.501538</td>\n",
       "      <td>0.492810</td>\n",
       "      <td>0.510564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.556929</td>\n",
       "      <td>0.529521</td>\n",
       "      <td>0.728596</td>\n",
       "      <td>0.650769</td>\n",
       "      <td>0.378533</td>\n",
       "      <td>0.255539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
       "0          0.738572             0.596996                   0.651436   \n",
       "1          0.735816             0.630617                   0.625565   \n",
       "2          0.569044             0.616224                   0.791176   \n",
       "3          0.588154             0.755139                   0.519233   \n",
       "4          0.556929             0.529521                   0.728596   \n",
       "\n",
       "   Avg. Area Number of Bedrooms  Area Population     Price  \n",
       "0                      0.629231         0.331603  0.428921  \n",
       "1                      0.475385         0.577019  0.609903  \n",
       "2                      0.789231         0.529751  0.428902  \n",
       "3                      0.501538         0.492810  0.510564  \n",
       "4                      0.650769         0.378533  0.255539  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_abs = np.max(np.abs(df), axis=0)\n",
    "\n",
    "scaled_df = df / max_abs\n",
    "\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95819fce",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **2. Min-Max Scaling**\n",
    "\n",
    "Min-Max Scaling transforms feature values by **subtracting the minimum value** of the feature and **dividing by the range** (maximum − minimum).\n",
    "This method maps the values to a specified range—commonly **0 to 1**—while preserving the original distribution shape.\n",
    "However, it is **sensitive to outliers**, since it relies on extreme values.\n",
    "\n",
    "---\n",
    "\n",
    "### **Formula**\n",
    "\n",
    "```text\n",
    "X_scaled = (Xi - Xmin) / (Xmax - Xmin)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Characteristics**\n",
    "\n",
    "* Scales features to a defined range (commonly **0 to 1**)\n",
    "* Preserves the original distribution's shape\n",
    "* **Sensitive to outliers**, as min and max can be influenced by extreme values\n",
    "\n",
    "---\n",
    "\n",
    "## **Code Example: Performing Min-Max Scaling**\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Create MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit scaler to the data and transform\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# Convert the scaled output back to a DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "\n",
    "# Display first few rows\n",
    "scaled_df.head()\n",
    "```\n",
    "\n",
    "### **Explanation**\n",
    "\n",
    "* Creates a **MinMaxScaler** object to scale values to the selected range\n",
    "* Uses `scaler.fit_transform(df)` to scale the data\n",
    "* Converts the result to a DataFrame to maintain column names\n",
    "* Shows the first few scaled rows using `scaled_df.head()`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab459062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:11: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 2.3.3)\n",
      "  from scipy.sparse import csr_matrix, issparse\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Area Income</th>\n",
       "      <th>Avg. Area House Age</th>\n",
       "      <th>Avg. Area Number of Rooms</th>\n",
       "      <th>Avg. Area Number of Bedrooms</th>\n",
       "      <th>Area Population</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.686822</td>\n",
       "      <td>0.441986</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.464444</td>\n",
       "      <td>0.329942</td>\n",
       "      <td>0.425210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.683521</td>\n",
       "      <td>0.488538</td>\n",
       "      <td>0.464501</td>\n",
       "      <td>0.242222</td>\n",
       "      <td>0.575968</td>\n",
       "      <td>0.607369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.483737</td>\n",
       "      <td>0.468609</td>\n",
       "      <td>0.701350</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>0.528582</td>\n",
       "      <td>0.425192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.506630</td>\n",
       "      <td>0.660956</td>\n",
       "      <td>0.312430</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.491549</td>\n",
       "      <td>0.507384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.469223</td>\n",
       "      <td>0.348556</td>\n",
       "      <td>0.611851</td>\n",
       "      <td>0.495556</td>\n",
       "      <td>0.376988</td>\n",
       "      <td>0.250702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
       "0          0.686822             0.441986                   0.501502   \n",
       "1          0.683521             0.488538                   0.464501   \n",
       "2          0.483737             0.468609                   0.701350   \n",
       "3          0.506630             0.660956                   0.312430   \n",
       "4          0.469223             0.348556                   0.611851   \n",
       "\n",
       "   Avg. Area Number of Bedrooms  Area Population     Price  \n",
       "0                      0.464444         0.329942  0.425210  \n",
       "1                      0.242222         0.575968  0.607369  \n",
       "2                      0.695556         0.528582  0.425192  \n",
       "3                      0.280000         0.491549  0.507384  \n",
       "4                      0.495556         0.376988  0.250702  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8ac6a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **3. Normalization (Vector Normalization)**\n",
    "\n",
    "Normalization scales each data sample (**row**) such that its **vector length (Euclidean norm)** becomes **1**.\n",
    "This technique focuses on the **direction** of data points rather than their magnitude, making it highly effective for algorithms where **angle** or **cosine similarity** is important, such as:\n",
    "\n",
    "* Text classification\n",
    "* Clustering\n",
    "* Recommendation systems\n",
    "\n",
    "---\n",
    "\n",
    "### **Formula**\n",
    "\n",
    "```text\n",
    "X_scaled = Xi / ||X||\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "* **Xi** → each individual feature value\n",
    "* **||X||** → Euclidean norm (length) of the vector **X**\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Characteristics**\n",
    "\n",
    "* Normalizes each sample to **unit length (1)**\n",
    "* Focuses on direction rather than magnitude\n",
    "* Ideal for similarity-based algorithms (e.g., cosine similarity)\n",
    "\n",
    "---\n",
    "\n",
    "## **Code Example: Performing Normalization**\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import pandas as pd\n",
    "\n",
    "# Create Normalizer object\n",
    "normalizer = Normalizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "normalized_data = normalizer.fit_transform(df)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=df.columns)\n",
    "\n",
    "# Display first few rows\n",
    "normalized_df.head()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Explanation**\n",
    "\n",
    "* Each row (sample) is scaled to have **unit norm**\n",
    "* Normalization emphasizes the **direction** of data points\n",
    "* Ideal for algorithms relying on **distance**, **angles**, or **cosine similarity**\n",
    "* `normalized_df.head()` shows normalized data where **each row is scaled individually**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97108286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Area Income</th>\n",
       "      <th>Avg. Area House Age</th>\n",
       "      <th>Avg. Area Number of Rooms</th>\n",
       "      <th>Avg. Area Number of Bedrooms</th>\n",
       "      <th>Area Population</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.074883</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.021734</td>\n",
       "      <td>0.996955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052534</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.026631</td>\n",
       "      <td>0.998264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057742</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.034749</td>\n",
       "      <td>0.997727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050168</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.027173</td>\n",
       "      <td>0.998371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.094559</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.041546</td>\n",
       "      <td>0.994652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
       "0          0.074883             0.000005                   0.000007   \n",
       "1          0.052534             0.000004                   0.000004   \n",
       "2          0.057742             0.000006                   0.000008   \n",
       "3          0.050168             0.000006                   0.000004   \n",
       "4          0.094559             0.000008                   0.000012   \n",
       "\n",
       "   Avg. Area Number of Bedrooms  Area Population     Price  \n",
       "0                      0.000004         0.021734  0.996955  \n",
       "1                      0.000002         0.026631  0.998264  \n",
       "2                      0.000005         0.034749  0.997727  \n",
       "3                      0.000003         0.027173  0.998371  \n",
       "4                      0.000007         0.041546  0.994652  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e7d1e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **What is Feature Extraction?**\n",
    "\n",
    "Feature extraction is the process of **transforming raw data** into a simplified, informative set of features.\n",
    "This reduces data complexity and highlights the most relevant information, making it easier for machine learning models to analyze patterns and learn efficiently.\n",
    "\n",
    "Feature extraction improves **model accuracy**, reduces **computational costs**, and focuses learning on the most essential aspects of the data.\n",
    "\n",
    "---\n",
    "\n",
    "## **Importance of Feature Extraction**\n",
    "\n",
    "Feature extraction is important for several reasons:\n",
    "\n",
    "### **1. Reduced Computational Cost**\n",
    "\n",
    "Raw data—especially images, audio, or large datasets—can be extremely complex.\n",
    "Feature extraction simplifies the data, reducing memory usage and processing requirements.\n",
    "\n",
    "### **2. Improved Model Performance**\n",
    "\n",
    "By focusing on the most relevant information, models achieve **higher accuracy** and learn more effectively.\n",
    "\n",
    "### **3. Better Insights**\n",
    "\n",
    "Reducing the number of features eliminates noise and irrelevant information, helping in deeper data understanding.\n",
    "\n",
    "### **4. Prevention of Overfitting**\n",
    "\n",
    "Too many features may cause a model to memorize the training data.\n",
    "Feature extraction simplifies the dataset, increasing generalization and reducing overfitting risk.\n",
    "\n",
    "---\n",
    "\n",
    "# **Key Techniques for Feature Extraction**\n",
    "\n",
    "Feature extraction methods vary based on data type and problem requirements.\n",
    "Below are some widely used techniques:\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Statistical Methods**\n",
    "\n",
    "Statistical methods summarize and describe essential patterns in the data.\n",
    "\n",
    "**Common attributes include:**\n",
    "\n",
    "* **Mean:** Average value of a dataset\n",
    "* **Median:** Middle value after sorting\n",
    "* **Standard Deviation:** Measures spread or dispersion\n",
    "* **Correlation & Covariance:** Show relationships between variables\n",
    "* **Regression Analysis:** Models relationships between dependent and independent variables\n",
    "\n",
    "These techniques help represent the **central tendency**, **spread**, and **relationships** within a dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Dimensionality Reduction**\n",
    "\n",
    "Dimensionality reduction simplifies datasets by reducing the number of features while preserving important information.\n",
    "\n",
    "Popular methods include:\n",
    "\n",
    "### **• Principal Component Analysis (PCA)**\n",
    "\n",
    "Identifies components that capture the most variance in the data.\n",
    "\n",
    "### **• Linear Discriminant Analysis (LDA)**\n",
    "\n",
    "Maximizes class separability by finding optimal feature combinations.\n",
    "\n",
    "### **• t-Distributed Stochastic Neighbor Embedding (t-SNE)**\n",
    "\n",
    "Reduces high-dimensional data into 2D or 3D for visualization, especially useful for complex datasets.\n",
    "\n",
    "# **Choosing the Right Method**\n",
    "\n",
    "Selecting an appropriate feature extraction method depends on:\n",
    "\n",
    "* Type of data (images, text, signals, tabular data)\n",
    "* Objective of the ML task\n",
    "* Available computational resources\n",
    "* Domain knowledge and expertise\n",
    "\n",
    "### **Challenges**\n",
    "\n",
    "* **Information Loss:** Simplifying data may remove important details\n",
    "* **Computational Complexity:** Some methods are resource-heavy, especially for large datasets\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754bc049",
   "metadata": {},
   "source": [
    "\n",
    "# **What is Feature Engineering?**\n",
    "\n",
    "Feature Engineering is the process of **selecting, creating, or modifying features**—the input variables—to help machine learning models learn patterns more effectively.\n",
    "It transforms raw, messy data into **meaningful, structured inputs** that improve model accuracy, performance, and reliability.\n",
    "\n",
    "---\n",
    "\n",
    "Feature engineering may involve tasks such as handling missing values, encoding categorical variables, scaling numerical features, creating new features, or combining existing ones.\n",
    "\n",
    "---\n",
    "\n",
    "# **Importance of Feature Engineering**\n",
    "\n",
    "Feature engineering can significantly influence the quality and performance of machine learning models.\n",
    "\n",
    "### **Benefits**\n",
    "\n",
    "* **Improve Accuracy**\n",
    "  Selecting and creating the right features helps the model learn better, resulting in more accurate predictions.\n",
    "\n",
    "* **Reduce Overfitting**\n",
    "  Using fewer but more important features helps the model generalize and avoid memorizing the data.\n",
    "\n",
    "* **Boost Interpretability**\n",
    "  Well-crafted features make it easier to understand how the model makes decisions.\n",
    "\n",
    "* **Enhance Efficiency**\n",
    "  Focusing on meaningful features reduces training time and computational cost.\n",
    "\n",
    "---\n",
    "\n",
    "# **Processes Involved in Feature Engineering**\n",
    "\n",
    "Below are core processes used in feature engineering:\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Feature Creation**\n",
    "\n",
    "Feature creation involves generating new features using:\n",
    "\n",
    "* **Domain Knowledge:** Based on industry or business rules\n",
    "* **Data-Driven Insights:** Derived by observing patterns\n",
    "* **Synthetic Features:** Combining or transforming existing variables\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Feature Transformation**\n",
    "\n",
    "Adjusts features to improve model performance:\n",
    "\n",
    "* **Normalization & Scaling**\n",
    "* **Encoding Categorical Data** (e.g., one-hot encoding)\n",
    "* **Mathematical Transformations**\n",
    "\n",
    "  * Log transformations for skewed distributions\n",
    "  * Polynomial transformations\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Feature Extraction**\n",
    "\n",
    "Extracts meaningful information while reducing dimensionality:\n",
    "\n",
    "* **Dimensionality Reduction (PCA, LDA)**\n",
    "* **Aggregation & Combination** (sum, average, ratios)\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Feature Selection**\n",
    "\n",
    "Chooses the most impactful subset of features:\n",
    "\n",
    "* **Filter Methods** (correlation, chi-square, ANOVA)\n",
    "* **Wrapper Methods** (forward selection, RFE)\n",
    "* **Embedded Methods** (Lasso, tree-based methods)\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Feature Scaling**\n",
    "\n",
    "Ensures all features contribute equally to the model:\n",
    "\n",
    "* **Min-Max Scaling** (0–1 range)\n",
    "* **Standard Scaling** (mean = 0, variance = 1)\n",
    "\n",
    "---\n",
    "\n",
    "# **Steps in Feature Engineering**\n",
    "\n",
    "Although steps may vary by problem, the general workflow includes:\n",
    "\n",
    "### **1. Data Cleaning**\n",
    "\n",
    "Identify and correct missing values, inconsistencies, and errors to maintain data quality.\n",
    "\n",
    "### **2. Data Transformation**\n",
    "\n",
    "Prepare data for modeling by applying scaling, normalization, encoding, and formatting.\n",
    "\n",
    "### **3. Feature Extraction**\n",
    "\n",
    "Create new features by deriving or combining existing ones to provide more meaningful input to the model.\n",
    "\n",
    "### **4. Feature Selection**\n",
    "\n",
    "Choose relevant features using techniques like correlation analysis, mutual information, or stepwise regression.\n",
    "\n",
    "### **5. Feature Iteration**\n",
    "\n",
    "Refine features continuously based on model performance—adding, removing, or modifying features to improve results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb4cc7f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Feature Selection Techniques in Machine Learning**\n",
    "\n",
    "**Last Updated:** 20 Nov, 2025\n",
    "\n",
    "Feature selection is the process of choosing the **most useful** input features for a machine learning model.\n",
    "It helps improve performance, reduces noise, and makes results easier to interpret.\n",
    "\n",
    "---\n",
    "\n",
    "## **Why Feature Selection Is Important**\n",
    "\n",
    "Feature selection plays a vital role in building efficient ML models:\n",
    "\n",
    "* Removes irrelevant and redundant features\n",
    "* Improves accuracy and reduces overfitting\n",
    "* Speeds up training and prediction\n",
    "* Makes models simpler and more interpretable\n",
    "\n",
    "---\n",
    "\n",
    "## **Need for Feature Selection**\n",
    "\n",
    "Feature selection methods are essential for the following reasons:\n",
    "\n",
    "* **Improved Accuracy:** Models perform better with relevant inputs.\n",
    "* **Faster Training:** Fewer features reduce computational time.\n",
    "* **Greater Interpretability:** Easier to understand model behavior.\n",
    "* **Avoiding Curse of Dimensionality:** Reduces complexity in high-dimensional datasets.\n",
    "\n",
    "---\n",
    "\n",
    "# **Types of Feature Selection Methods**\n",
    "\n",
    "Feature selection techniques are grouped into **three main categories**, each offering different advantages depending on the use case.\n",
    "\n",
    "---\n",
    "\n",
    "# **1. Filter Methods**\n",
    "\n",
    "Filter methods evaluate each feature **independently of the model** by measuring its relationship with the target variable.\n",
    "They are used during preprocessing to remove irrelevant or redundant features based on **statistical tests** or other criteria.\n",
    "\n",
    "### **Common Filter Techniques**\n",
    "\n",
    "* **Information Gain** – Measures entropy reduction\n",
    "* **Chi-square Test** – Evaluates relationships in categorical data\n",
    "* **Fisher’s Score** – Ranks features based on class separability\n",
    "* **Pearson Correlation Coefficient** – Linear relationship between continuous variables\n",
    "* **Variance Threshold** – Removes features with low variance\n",
    "* **Mean Absolute Difference** – Measures variability\n",
    "* **Dispersion Ratio** – Compares arithmetic mean to geometric mean\n",
    "\n",
    "### **Advantages**\n",
    "\n",
    "* Fast and computationally efficient\n",
    "* Easy to implement\n",
    "* Works with any ML model (model-independent)\n",
    "\n",
    "### **Limitations**\n",
    "\n",
    "* Doesn’t consider feature interactions\n",
    "* Performance depends on choosing the right statistical metric\n",
    "\n",
    "---\n",
    "\n",
    "# **2. Wrapper Methods**\n",
    "\n",
    "Wrapper methods evaluate feature subsets by **training a model** and selecting combinations that improve performance.\n",
    "They try various feature combinations and choose the best-performing subset.\n",
    "\n",
    "### **Common Wrapper Techniques**\n",
    "\n",
    "* **Forward Selection** – Begin with no features, add one at a time\n",
    "* **Backward Elimination** – Begin with all features, remove one at a time\n",
    "* **Recursive Feature Elimination (RFE)** – Repeatedly remove least important features\n",
    "\n",
    "### **Advantages**\n",
    "\n",
    "* Model-specific optimization\n",
    "* Leads to potentially better performance\n",
    "* Flexible with different evaluation metrics\n",
    "\n",
    "### **Limitations**\n",
    "\n",
    "* Computationally expensive\n",
    "* Risk of overfitting\n",
    "* Not suitable for large datasets\n",
    "\n",
    "---\n",
    "\n",
    "# **3. Embedded Methods**\n",
    "\n",
    "Embedded methods perform feature selection **during the model training process**, combining the strengths of filter and wrapper methods.\n",
    "\n",
    "### **Common Embedded Techniques**\n",
    "\n",
    "* **L1 Regularization (Lasso Regression)** – Removes features with zero coefficients\n",
    "* **Decision Trees & Random Forests** – Select features based on impurity reduction\n",
    "* **Gradient Boosting Models** – Choose features that reduce prediction error\n",
    "\n",
    "### **Advantages**\n",
    "\n",
    "* Efficient and computationally lighter than wrapper methods\n",
    "* Model learns feature importance automatically during training\n",
    "\n",
    "### **Limitations**\n",
    "\n",
    "* Less interpretable than filter methods\n",
    "* Not all algorithms support embedded feature selection\n",
    "\n",
    "---\n",
    "\n",
    "# **Choosing the Right Feature Selection Method**\n",
    "\n",
    "The best method depends on the following factors:\n",
    "\n",
    "* **Dataset Size:**\n",
    "\n",
    "  * Large datasets → *Filter methods*\n",
    "  * Small datasets → *Wrapper methods*\n",
    "\n",
    "* **Model Type:**\n",
    "\n",
    "  * Tree-based models have built-in feature selection\n",
    "\n",
    "* **Interpretability Needs:**\n",
    "\n",
    "  * Use *filter methods* if transparency is important\n",
    "\n",
    "* **Computational Resources:**\n",
    "\n",
    "  * Wrapper methods are resource-intensive\n",
    "\n",
    "---\n",
    "\n",
    "By applying the right feature selection techniques, we can **improve model performance**, **reduce computation**, and **build more reliable machine learning systems**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8550a3ea",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
